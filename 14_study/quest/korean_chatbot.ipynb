{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8KJOB6nYFM_0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4GcAasBtK810"
   },
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rOpAvZAUWOXB"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9Bsr8aVYYHW"
   },
   "source": [
    "## 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wKvoPX2JXdXQ"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0HhfoVMXodt",
    "outputId": "46d4f5ea-4677-4f34-d765-183c4d539250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVnw6gbeXqfZ"
   },
   "source": [
    "## Look ahead masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v9nR-ArIYfHc"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oj5lzJkCYhx-",
    "outputId": "c3599fe8-0c0f-4235-c7c5-94d5eba2d705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPUBqwjMYjFL",
    "outputId": "8724b7c3-761f-429c-ee03-cadb5cd30ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7VlmBBvYlrC"
   },
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hO43GH4IY6GY"
   },
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KMMN7c4EY66J"
   },
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORQQN36NZg52"
   },
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TbaSVIEbZO0B"
   },
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AGSiGrXlZf6N"
   },
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utlefkPKZvXu"
   },
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/aiffel/aiffel/workspace/14_study/quest/data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 갯수 11823\n",
      "결측치\n",
      " Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('전체 갯수',len(data))\n",
    "print('결측치\\n', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(df):\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in df:\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        sentence = sentence.strip()\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = preprocess_sentence(data['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = preprocess_sentence(data['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [8005, 7990, 2192, 919, 78, 821]\n",
      "기존 문장: SD카드 망가졌어\n"
     ]
    }
   ],
   "source": [
    "# SubWord Text Tokenizer encode decode 확인\n",
    "\n",
    "org_string = questions[5]\n",
    "\n",
    "encode_string = tokenizer.encode(org_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(encode_string))\n",
    "\n",
    "decode_string = tokenizer.decode(encode_string)\n",
    "print ('기존 문장: {}'.format(decode_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8005 === S\n",
      "7990 === D\n",
      "2192 === 카드 \n",
      "919 === 망\n",
      "78 === 가\n",
      "821 === 졌어\n"
     ]
    }
   ],
   "source": [
    "# 각 정수는 각 단어와 어떻게 mapping되는지 출력\n",
    "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
    "for encode in encode_string:\n",
    "    print(f'{encode} === {tokenizer.decode([encode])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        #  정수 인코딩 + 시작 토큰과 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8180\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 0번째 샘플을 임의로 출력\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기(Vocab size): 8180\n",
      "전체 샘플의 수(Number of samples): 11823\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기(Vocab size): {}'.format(VOCAB_SIZE))\n",
    "print('전체 샘플의 수(Number of samples): {}'.format(len(questions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher forcing\n",
    "샘플 : \\<START_TOKEN> I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD> \\<PAD>\n",
    "\n",
    "입력 : \\<START_TOKEN> I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD>\n",
    "    \n",
    "레이블 : I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD> \\<PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 9458\n",
      "Validation dataset size: 2365\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨처음 시작 토큰 제거\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# 훈련데이터셋 검증 데이터셋 나누기\n",
    "\n",
    "# 데이터셋 크기 계산\n",
    "dataset_size = len(questions)\n",
    "\n",
    "# 2. 데이터셋 분할\n",
    "train_size = int(0.8 * dataset_size)  # 예시로 80%를 train으로 사용\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# 배치 및 프리페치 적용\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 3. 데이터셋 크기 확인\n",
    "print(f\"Train dataset size: {train_size}\")\n",
    "print(f\"Validation dataset size: {val_size}\")\n",
    "\n",
    "\n",
    "# dataset = dataset.batch(BATCH_SIZE)\n",
    "# dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3148288     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3675648     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8180)   2102260     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,926,196\n",
      "Trainable params: 8,926,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "UNITS = 512\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.3\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 17s 70ms/step - loss: 1.4882 - accuracy: 0.0198 - val_loss: 1.3606 - val_accuracy: 0.0397\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03966, saving model to best_weights.h5\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 1.2763 - accuracy: 0.0423 - val_loss: 1.1190 - val_accuracy: 0.0491\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.03966 to 0.04907, saving model to best_weights.h5\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 9s 63ms/step - loss: 1.0824 - accuracy: 0.0496 - val_loss: 1.0209 - val_accuracy: 0.0498\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.04907 to 0.04981, saving model to best_weights.h5\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 1.0092 - accuracy: 0.0501 - val_loss: 0.9656 - val_accuracy: 0.0508\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.04981 to 0.05082, saving model to best_weights.h5\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.9606 - accuracy: 0.0518 - val_loss: 0.9185 - val_accuracy: 0.0539\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.05082 to 0.05393, saving model to best_weights.h5\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.9255 - accuracy: 0.0542 - val_loss: 0.8894 - val_accuracy: 0.0558\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.05393 to 0.05581, saving model to best_weights.h5\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.8915 - accuracy: 0.0562 - val_loss: 0.8427 - val_accuracy: 0.0579\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.05581 to 0.05792, saving model to best_weights.h5\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.8563 - accuracy: 0.0579 - val_loss: 0.7976 - val_accuracy: 0.0605\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.05792 to 0.06047, saving model to best_weights.h5\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.8273 - accuracy: 0.0599 - val_loss: 0.7506 - val_accuracy: 0.0637\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.06047 to 0.06372, saving model to best_weights.h5\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.7843 - accuracy: 0.0626 - val_loss: 0.7057 - val_accuracy: 0.0676\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.06372 to 0.06756, saving model to best_weights.h5\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.7444 - accuracy: 0.0661 - val_loss: 0.6677 - val_accuracy: 0.0721\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.06756 to 0.07211, saving model to best_weights.h5\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.7020 - accuracy: 0.0701 - val_loss: 0.6046 - val_accuracy: 0.0792\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.07211 to 0.07923, saving model to best_weights.h5\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.6510 - accuracy: 0.0751 - val_loss: 0.5569 - val_accuracy: 0.0852\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.07923 to 0.08521, saving model to best_weights.h5\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.6035 - accuracy: 0.0800 - val_loss: 0.4950 - val_accuracy: 0.0911\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.08521 to 0.09114, saving model to best_weights.h5\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.5568 - accuracy: 0.0854 - val_loss: 0.4430 - val_accuracy: 0.0976\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.09114 to 0.09757, saving model to best_weights.h5\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.5102 - accuracy: 0.0901 - val_loss: 0.3945 - val_accuracy: 0.1057\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.09757 to 0.10570, saving model to best_weights.h5\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.4666 - accuracy: 0.0955 - val_loss: 0.3377 - val_accuracy: 0.1114\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.10570 to 0.11141, saving model to best_weights.h5\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 9s 63ms/step - loss: 0.4186 - accuracy: 0.1014 - val_loss: 0.3107 - val_accuracy: 0.1168\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.11141 to 0.11678, saving model to best_weights.h5\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 9s 63ms/step - loss: 0.3781 - accuracy: 0.1062 - val_loss: 0.2588 - val_accuracy: 0.1231\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.11678 to 0.12309, saving model to best_weights.h5\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.3429 - accuracy: 0.1104 - val_loss: 0.2345 - val_accuracy: 0.1288\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.12309 to 0.12882, saving model to best_weights.h5\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.3106 - accuracy: 0.1150 - val_loss: 0.1979 - val_accuracy: 0.1347\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.12882 to 0.13470, saving model to best_weights.h5\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.2797 - accuracy: 0.1198 - val_loss: 0.1771 - val_accuracy: 0.1389\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.13470 to 0.13888, saving model to best_weights.h5\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.2521 - accuracy: 0.1233 - val_loss: 0.1484 - val_accuracy: 0.1441\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.13888 to 0.14412, saving model to best_weights.h5\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.2277 - accuracy: 0.1270 - val_loss: 0.1320 - val_accuracy: 0.1458\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.14412 to 0.14580, saving model to best_weights.h5\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.2049 - accuracy: 0.1304 - val_loss: 0.1116 - val_accuracy: 0.1497\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.14580 to 0.14965, saving model to best_weights.h5\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1876 - accuracy: 0.1335 - val_loss: 0.0998 - val_accuracy: 0.1522\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.14965 to 0.15219, saving model to best_weights.h5\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1709 - accuracy: 0.1365 - val_loss: 0.0865 - val_accuracy: 0.1561\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.15219 to 0.15608, saving model to best_weights.h5\n",
      "Epoch 28/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1567 - accuracy: 0.1391 - val_loss: 0.0729 - val_accuracy: 0.1560\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.15608\n",
      "Epoch 29/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1415 - accuracy: 0.1420 - val_loss: 0.0637 - val_accuracy: 0.1600\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.15608 to 0.16000, saving model to best_weights.h5\n",
      "Epoch 30/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1267 - accuracy: 0.1450 - val_loss: 0.0534 - val_accuracy: 0.1617\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.16000 to 0.16175, saving model to best_weights.h5\n",
      "Epoch 31/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1154 - accuracy: 0.1475 - val_loss: 0.0440 - val_accuracy: 0.1609\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.16175\n",
      "Epoch 32/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.1036 - accuracy: 0.1493 - val_loss: 0.0398 - val_accuracy: 0.1666\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.16175 to 0.16657, saving model to best_weights.h5\n",
      "Epoch 33/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0953 - accuracy: 0.1523 - val_loss: 0.0339 - val_accuracy: 0.1672\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.16657 to 0.16719, saving model to best_weights.h5\n",
      "Epoch 34/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0876 - accuracy: 0.1529 - val_loss: 0.0290 - val_accuracy: 0.1691\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.16719 to 0.16907, saving model to best_weights.h5\n",
      "Epoch 35/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0809 - accuracy: 0.1548 - val_loss: 0.0269 - val_accuracy: 0.1691\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.16907\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0747 - accuracy: 0.1554 - val_loss: 0.0268 - val_accuracy: 0.1684\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.16907\n",
      "Epoch 37/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0688 - accuracy: 0.1574 - val_loss: 0.0206 - val_accuracy: 0.1705\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.16907 to 0.17047, saving model to best_weights.h5\n",
      "Epoch 38/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0645 - accuracy: 0.1586 - val_loss: 0.0201 - val_accuracy: 0.1689\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.17047\n",
      "Epoch 39/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0614 - accuracy: 0.1591 - val_loss: 0.0192 - val_accuracy: 0.1705\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.17047 to 0.17050, saving model to best_weights.h5\n",
      "Epoch 40/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0566 - accuracy: 0.1600 - val_loss: 0.0191 - val_accuracy: 0.1674\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.17050\n",
      "Epoch 41/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0530 - accuracy: 0.1610 - val_loss: 0.0169 - val_accuracy: 0.1720\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.17050 to 0.17198, saving model to best_weights.h5\n",
      "Epoch 42/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0501 - accuracy: 0.1614 - val_loss: 0.0172 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.17198\n",
      "Epoch 43/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0474 - accuracy: 0.1624 - val_loss: 0.0144 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.17198\n",
      "Epoch 44/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0460 - accuracy: 0.1632 - val_loss: 0.0117 - val_accuracy: 0.1736\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.17198 to 0.17361, saving model to best_weights.h5\n",
      "Epoch 45/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0423 - accuracy: 0.1647 - val_loss: 0.0113 - val_accuracy: 0.1736\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.17361 to 0.17362, saving model to best_weights.h5\n",
      "Epoch 46/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0408 - accuracy: 0.1645 - val_loss: 0.0117 - val_accuracy: 0.1731\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.17362\n",
      "Epoch 47/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0390 - accuracy: 0.1649 - val_loss: 0.0100 - val_accuracy: 0.1737\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.17362 to 0.17367, saving model to best_weights.h5\n",
      "Epoch 48/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0366 - accuracy: 0.1648 - val_loss: 0.0086 - val_accuracy: 0.1709\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.17367\n",
      "Epoch 49/50\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.0369 - accuracy: 0.1650 - val_loss: 0.0078 - val_accuracy: 0.1739\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.17367 to 0.17390, saving model to best_weights.h5\n",
      "Epoch 50/50\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.0344 - accuracy: 0.1659 - val_loss: 0.0085 - val_accuracy: 0.1717\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.17390\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "weight_filename = 'best_weights.h5'\n",
    "\n",
    "# ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    weight_filename,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "import os\n",
    "\n",
    "if os.path.isfile(weight_filename):\n",
    "    model.load_weights(weight_filename)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint,early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한 30번 이후로는 거의 변화가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련결과 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = input_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "              break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>그 시절엔 다 그랬지</td>\n",
       "      <td>추억에 잠길 때도 필요해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>듬직한 사람이 좋아</td>\n",
       "      <td>의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>오늘 좀 바쁘네</td>\n",
       "      <td>바빠도 힘내세요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>여자친구가 전화하는 걸 안 좋아해</td>\n",
       "      <td>다른 연락을 많이 하거나 더 자주 만나세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>좋아하는 사람 언제까지 기다릴 수 있을까요.</td>\n",
       "      <td>마음이 허락하는 데까지 아닐까요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>할 말이 많은데.</td>\n",
       "      <td>말해보세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>불금에 혼자 혼술</td>\n",
       "      <td>혼술 적당히 하세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>눈 또 와</td>\n",
       "      <td>눈 내리는게 싫은가 봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>위로받고 싶은 날</td>\n",
       "      <td>제가 위로 많이 해드릴게요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>부케 뭐로 하지</td>\n",
       "      <td>당신이 좋아하는 꽃으로 만들어보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Q                                 A  label\n",
       "306                 그 시절엔 다 그랬지                   추억에 잠길 때도 필요해요.      0\n",
       "1379                 듬직한 사람이 좋아  의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요.      0\n",
       "3313                   오늘 좀 바쁘네                         바빠도 힘내세요!      0\n",
       "3169         여자친구가 전화하는 걸 안 좋아해          다른 연락을 많이 하거나 더 자주 만나세요.      0\n",
       "11091  좋아하는 사람 언제까지 기다릴 수 있을까요.                마음이 허락하는 데까지 아닐까요.      2\n",
       "8467                  할 말이 많은데.                            말해보세요.      1\n",
       "6523                  불금에 혼자 혼술                       혼술 적당히 하세요.      1\n",
       "1061                      눈 또 와                    눈 내리는게 싫은가 봐요.      0\n",
       "3597                  위로받고 싶은 날                   제가 위로 많이 해드릴게요.      0\n",
       "2162                   부케 뭐로 하지              당신이 좋아하는 꽃으로 만들어보세요.      0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(10)\n",
    "test_question = test['Q']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Input: 그 시절엔 다 그랬지\n",
      "Output: 추억에 잠길 때도 필요해요 .\n",
      "------------------------------\n",
      "Input: 듬직한 사람이 좋아\n",
      "Output: 의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요 .\n",
      "------------------------------\n",
      "Input: 오늘 좀 바쁘네\n",
      "Output: 바빠도 힘내세요 !\n",
      "------------------------------\n",
      "Input: 여자친구가 전화하는 걸 안 좋아해\n",
      "Output: 다른 연락을 많이 하거나 더 자주 만나세요 .\n",
      "------------------------------\n",
      "Input: 좋아하는 사람 언제까지 기다릴 수 있을까요.\n",
      "Output: 마음이 허락하는 데까지 아닐까요 .\n",
      "------------------------------\n",
      "Input: 할 말이 많은데.\n",
      "Output: 말해보세요 .\n",
      "------------------------------\n",
      "Input: 불금에 혼자 혼술\n",
      "Output: 혼술 적당히 하세요 .\n",
      "------------------------------\n",
      "Input: 눈 또 와\n",
      "Output: 눈 내리는게 싫은가 봐요 .\n",
      "------------------------------\n",
      "Input: 위로받고 싶은 날\n",
      "Output: 제가 위로 많이 해드릴게요 .\n",
      "------------------------------\n",
      "Input: 부케 뭐로 하지\n",
      "Output: 당신이 좋아하는 꽃으로 만들어보세요 .\n"
     ]
    }
   ],
   "source": [
    "for question in test_question:\n",
    "    print('-'*30)\n",
    "    sentence_generation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Input: 그시절엔 다그랬나\n",
      "Output: 추억에 잠길 때도 필요해요 .\n",
      "------------------------------\n",
      "Input: 듬직한 사람이 좋아?\n",
      "Output: 의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요 .\n",
      "------------------------------\n",
      "Input: 바쁘다\n",
      "Output: 바빠도 힘내세요 !\n",
      "------------------------------\n",
      "Input: 좋아하는 사람 언제까지 기다릴 수 있을까?\n",
      "Output: 작은 것 하나라도 챙겨준다면 센스있는 사람이라고 생각할 거예요 .\n",
      "------------------------------\n",
      "Input: 할 말이 많음\n",
      "Output: 다른일로 바쁘면 조금 덜할 거예요 .\n",
      "------------------------------\n",
      "Input: 나는 혼술이 좋아\n",
      "Output: 캬아 맛있는 안주랑 드세요\n",
      "------------------------------\n",
      "Input: 혼술중\n",
      "Output: 캬아 맛있는 안주랑 드세요\n",
      "------------------------------\n",
      "Input: 눈이또와\n",
      "Output: 잠시 거리를 두고 생각해보세요 .\n",
      "------------------------------\n",
      "Input: 나 우울해 위로해줘\n",
      "Output: 많이 힘들었죠 .\n",
      "------------------------------\n",
      "Input: 부케가 뭘로할까\n",
      "Output: 잘 골라보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 골라보세요 .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-'*30)\n",
    "sentence_generation('그시절엔 다그랬나')\n",
    "print('-'*30)\n",
    "sentence_generation('듬직한 사람이 좋아?')\n",
    "print('-'*30)\n",
    "sentence_generation('바쁘다')\n",
    "print('-'*30)\n",
    "sentence_generation('좋아하는 사람 언제까지 기다릴 수 있을까?')\n",
    "print('-'*30)\n",
    "sentence_generation('할 말이 많음')\n",
    "print('-'*30)\n",
    "sentence_generation('나는 혼술이 좋아')\n",
    "print('-'*30)\n",
    "sentence_generation('혼술중')\n",
    "print('-'*30)\n",
    "sentence_generation('눈이또와')\n",
    "print('-'*30)\n",
    "sentence_generation('나 우울해 위로해줘')\n",
    "print('-'*30)\n",
    "sentence_generation('부케가 뭘로할까')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 배운점\n",
    "    - 한국어를 이해할 수 있게 하는 원리 (인코더 디코더 어텐션 등)\n",
    "- 아쉬운점\n",
    "    - Q: 할 말이 많음 A: 다른일로 바쁘면 조금 덜할 거예요. 처럼 답변이 이상한 답변이 있다.\n",
    "- 어려웠던점\n",
    "    - keras tuner로 최적의 하이퍼 파라미터를 찾아주고 싶었는데 이는 적용하지 못했고 수동으로 바꿔주었다.\n",
    "- 느낀점\n",
    "    - 다른 팀원분은 데이터 전처리 과정에서 숫자 없애거나 말거나 (박 일 / 3박4일) -> 와 같은 전처리를 추가로 진행하신 분도 있었는데 나는 그런부분까지는 생각하지 못했던거같다. 전처리 과정에 좀더 다른 전처리가 필요하지 않을까? 라는 궁금증을 가져야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
